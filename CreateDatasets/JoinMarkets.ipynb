{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here qe load all jsons and all excels and create a unqiue csv file per market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allyears = ['../datasets/Dataset_Mayy2019', \n",
    "            '../datasets/Dataset_July2020', \n",
    "            '../datasets/Dataset_Apri2021']\n",
    "excelpaths = ['../datasets/Dataset_Mayy2019/Dataset_Mayy2019_traceability.csv',\n",
    "              '../datasets/Dataset_July2020/Dataset_july2020_traceability.csv',\n",
    "              '../datasets/Dataset_Apri2021/Dataset_April2021_traceability.csv',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "def getFiles(dirName):\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    completeFileList = list()\n",
    "    for file in listOfFile:\n",
    "        completePath = os.path.join(dirName, file)\n",
    "        if os.path.isdir(completePath):\n",
    "            completeFileList = completeFileList + getFiles(completePath)\n",
    "        elif 'file.json' in completePath:\n",
    "            completeFileList.append(completePath.replace('\\\\', '/'))\n",
    "\n",
    "    return completeFileList\n",
    "\n",
    "#load all objects in the json files in a dictoinary with key = filepath\n",
    "import json\n",
    "def loadObjects(jsonPath):\n",
    "    lines = open(jsonPath, 'r').readlines() \n",
    "    allobj = []\n",
    "    try:\n",
    "        for line in lines: \n",
    "            if(len(line.strip()) > 0):\n",
    "                allobj.append( json.loads(line) )\n",
    "    except:\n",
    "        pass\n",
    "    return allobj\n",
    "\n",
    "def _createSkillDict(oldd, market, year):\n",
    "    '''\n",
    "    example json obj\n",
    "    {'Main Category': 'Business & Finance', 'SubCategory': 'Business & Finance', 'Sample_Invocation_Utterances': [\"“'Alexa, Open Current Bitcoin'”\", \"“'Alexa, Ask Current Bitcoin for Prices'”\", \"“'Alexa, Ask Current Bitcoin what the price is'”\"], 'Name': 'CurrentBitcoin', 'Developer': 'by Sarim Studios', 'Skill_permission': [], 'Account_linking': '', 'Review_Count': None, 'Rating': '', 'Total_customer_that_rate_the_skill': '0', 'Total_Customers_Reviews': 'No customer reviews', 'Cost': 'Free to Enable', 'In_skill_purchase': None, 'Skill_description': \"Description\\nAn 'easy to use' Alexa skill that will provide you with the latest price for a bitcoin. This skill uses BitStamp's latest prices, which are always up-to-date. All you have to do to begin using the skill is ask Alexa, Ask Current Bitcoin for Prices. Price is given in USD.\", 'Skill_link': 'https://www.amazon.ca/Sarim-Studios-CurrentBitcoin/dp/B01N9SS2LI/ref=sr_1_635?dchild=1&fst=as%3Aoff&qid=1595709096&rnid=16286270011&s=alexa-skills&sr=1-635', 'privacy_policy and Terms_of_use specified': 'No privacy_policy and Terms_of_use specified'}\n",
    "    '''\n",
    "    newd = {}    \n",
    "    for obj in oldd:\n",
    "        if len(obj) == 0:\n",
    "            continue\n",
    "            \n",
    "        name = ''\n",
    "        if 'Name' in obj:\n",
    "            name = obj['Name'].strip()\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        inskill = ''\n",
    "        if 'In_skill_purchase' in obj:\n",
    "            inskill = obj['In_skill_purchase']\n",
    "            if(inskill is not None):\n",
    "                inskill = inskill.strip()\n",
    "        \n",
    "        linking = ''\n",
    "        if 'Account_linking' in obj:\n",
    "            linking = obj['Account_linking']\n",
    "            if(linking is not None):\n",
    "                linking = linking.strip()\n",
    "            \n",
    "        dev = ''\n",
    "        if 'Developer' in obj:\n",
    "            dev = obj['Developer']\n",
    "            if(dev is not None):\n",
    "                dev = dev.strip()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        total_rev=''\n",
    "        if 'Total_Customers_Reviews' in obj:\n",
    "            total_rev = obj['Total_Customers_Reviews']\n",
    "            if(total_rev is not None):\n",
    "                total_rev = total_rev.strip()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        skill_id = ''\n",
    "        if 'Skill_link' in obj:\n",
    "            try:\n",
    "                skill_url = obj['Skill_link']\n",
    "                skill_id = re.search(r\"\\b[B]+[0-9]+(?:[A-Z0-9]+/)+\", skill_url).group().replace('/','')\n",
    "                if(skill_id is not None):\n",
    "                    skill_id = skill_id.strip()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        maincat = ''\n",
    "        if 'Main Category' in obj:\n",
    "            maincat = obj['Main Category']\n",
    "            if(maincat is not None):\n",
    "                maincat = maincat.strip()\n",
    "        \n",
    "        cost = ''\n",
    "        if 'Cost' in obj:\n",
    "            cost = obj['Cost']\n",
    "            if(cost is not None):\n",
    "                cost = cost.strip()\n",
    "            \n",
    "        subcat = ''\n",
    "        if 'SubCategory' in obj:\n",
    "            subcat = obj['SubCategory']\n",
    "            if(subcat is not None):\n",
    "                subcat = subcat.strip()\n",
    "        \n",
    "        perm = obj['Skill_permission']\n",
    "\n",
    "        \n",
    "        skill_link = ''\n",
    "        if 'Skill_link' in obj:\n",
    "            skill_link = obj['Skill_link']\n",
    "            if(skill_link is not None):\n",
    "                skill_link = skill_link.strip()\n",
    "        \n",
    "        policy = ''\n",
    "        if 'privacy_policy' in obj:\n",
    "            policy = obj['privacy_policy']\n",
    "            \n",
    "        #we use id_aux as a unique identifier between yearly datasets\n",
    "        id_aux = name+'__'+ dev +'__'+ skill_id\n",
    "        \n",
    "        newd[id_aux] = {\n",
    "             'id_name_dev'  : name+'__'+ dev,\n",
    "             'id_aux'  :id_aux,\n",
    "             'id'      :skill_id,\n",
    "             'name'    :name,\n",
    "             'dev'     :dev,\n",
    "             'cat'     :maincat,\n",
    "             'market'  :market,\n",
    "             'subcat'  :subcat,\n",
    "             'acc_linking':linking,\n",
    "             'in_skill_purchase':inskill,\n",
    "             'cost':cost,\n",
    "             'review_stars':total_rev,\n",
    "             'skill_link':skill_link,\n",
    "             'policy':policy,\n",
    "             'policy_url':None,\n",
    "             'policy_text':None,\n",
    "             'perm_requested_norm':None,\n",
    "             'perm_found_norm':None,\n",
    "             'perm_requested_original':None,\n",
    "             'traceability':None,\n",
    "             'year':year}\n",
    "         \n",
    "        \n",
    "        \n",
    "        \n",
    "    return newd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reloadData(path):\n",
    "    def getFiles(dirName):\n",
    "        listOfFile = os.listdir(dirName)\n",
    "        completeFileList = list()\n",
    "        for file in listOfFile:\n",
    "            completePath = os.path.join(dirName, file)\n",
    "            if os.path.isdir(completePath):\n",
    "                completeFileList = completeFileList + getFiles(completePath)\n",
    "            elif '.json' in completePath:\n",
    "                completeFileList.append(completePath.replace('\\\\', '/'))\n",
    "\n",
    "        return completeFileList\n",
    "\n",
    "    allf = getFiles( path )\n",
    "    print(allf)\n",
    "\n",
    "    #create dictionary of markets and skills\n",
    "    skillsmarketd = {}\n",
    "    for f in allf:\n",
    "        marketname = f.split('/')[4].split('.json')[0]\n",
    "        with open(f, 'r') as json_file:\n",
    "            skillsmarketd[marketname] = json.load(json_file)\n",
    "\n",
    "    print()\n",
    "    print('Total unique skills per market')\n",
    "    for key,value in skillsmarketd.items():\n",
    "        print(key, \": \", len(value))\n",
    "    print()\n",
    "    print()\n",
    "    return skillsmarketd\n",
    "\n",
    "def loadExcelFile(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['unique_id'] = df['Name']+'__'+df['Developer']\n",
    "    return df\n",
    "\n",
    "def updateDataframe(skillsobject, t_df):\n",
    "    '''\n",
    "    skillsobject : object as returned by reloadData function\n",
    "    t_df : tracability dataframe, as returned by loadExcelFile\n",
    "    '''\n",
    "    \n",
    "    #first transform the disctionary of objects into a list of objects :)\n",
    "    finallist = []\n",
    "    for market in skillsobject:\n",
    "        skills = skillsobject[market]\n",
    "        for skill in skills:\n",
    "            finallist.append( skills[skill] )\n",
    "    df_aux = pd.DataFrame([x for x in finallist])\n",
    "    \n",
    "    #we need to fill in the blanks for #policy, policy_url, policy_text, \n",
    "    # perm_requested, perm_found, perm_requested_original, traceability with t_df\n",
    "    t_df.rename(columns = {'unique_id':'id_name_dev'}, inplace = True)\n",
    "    t_df = t_df.drop(['Developer', 'Name', 'acc_linking', 'cat',\n",
    "           'in_skill_purchase',\n",
    "           'subcat'], axis = 1)\n",
    "\n",
    "    df_aux = df_aux.drop(['traceability','policy_url', 'policy_text', 'perm_requested_original', 'perm_found_norm',\n",
    "       'perm_requested_norm'], axis = 1)\n",
    "    mergedDf = df_aux.merge(t_df,how='left', on='id_name_dev')\n",
    "\n",
    "   \n",
    "    mergedDf.rename(columns = {'privacy_policy':'policy_url'}, inplace = True)\n",
    "    mergedDf.rename(columns = {'privacy_policy_doc':'policy_text'}, inplace = True)\n",
    "    mergedDf.rename(columns = {'Skill_permission':'perm_requested_original'}, inplace = True)\n",
    "    mergedDf.rename(columns = {'perm_found':'perm_found_norm'}, inplace = True)\n",
    "    mergedDf.rename(columns = {'permissions_requested_adapt':'perm_requested_norm'}, inplace = True)\n",
    "    mergedDf = mergedDf.drop(['policy'], axis = 1)\n",
    "        \n",
    "   \n",
    "    \n",
    "    return mergedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load datasets, clean duplicates, create processed dataset, load processed dataset and map traceabiulity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: \n",
    "    -skillls without name are discarded automatically\n",
    "    -skills without dev are discarded\n",
    "    -repeated skills (name+dev) are discarded automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 2019"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#! check 'year' at the end of this section, replace year if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load info from the 2019 json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../datasets/Dataset_Mayy2019/AU/file.json', '../datasets/Dataset_Mayy2019/CA/file.json', '../datasets/Dataset_Mayy2019/DE/file.json', '../datasets/Dataset_Mayy2019/ES/file.json', '../datasets/Dataset_Mayy2019/FR/file.json', '../datasets/Dataset_Mayy2019/IN/file.json', '../datasets/Dataset_Mayy2019/IT/file.json', '../datasets/Dataset_Mayy2019/JP/file.json', '../datasets/Dataset_Mayy2019/MX/file.json', '../datasets/Dataset_Mayy2019/UK/file.json', '../datasets/Dataset_Mayy2019/US/file.json']\n",
      "../datasets/Dataset_Mayy2019/AU/file.json\n",
      "59311\n",
      "../datasets/Dataset_Mayy2019/CA/file.json\n",
      "156204\n",
      "../datasets/Dataset_Mayy2019/DE/file.json\n",
      "57521\n",
      "../datasets/Dataset_Mayy2019/ES/file.json\n",
      "60147\n",
      "../datasets/Dataset_Mayy2019/FR/file.json\n",
      "30010\n",
      "../datasets/Dataset_Mayy2019/IN/file.json\n",
      "92770\n",
      "../datasets/Dataset_Mayy2019/IT/file.json\n",
      "45458\n",
      "../datasets/Dataset_Mayy2019/JP/file.json\n",
      "78583\n",
      "../datasets/Dataset_Mayy2019/MX/file.json\n",
      "26438\n",
      "../datasets/Dataset_Mayy2019/UK/file.json\n",
      "159644\n",
      "../datasets/Dataset_Mayy2019/US/file.json\n",
      "679526\n",
      "********************\n",
      "AU\n",
      "#skills 23123\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/AU.json\n",
      "********************\n",
      "CA\n",
      "#skills 24700\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/CA.json\n",
      "********************\n",
      "DE\n",
      "#skills 8928\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/DE.json\n",
      "********************\n",
      "ES\n",
      "#skills 1286\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/ES.json\n",
      "********************\n",
      "FR\n",
      "#skills 1341\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/FR.json\n",
      "********************\n",
      "IN\n",
      "#skills 20989\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/IN.json\n",
      "********************\n",
      "IT\n",
      "#skills 2210\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/IT.json\n",
      "********************\n",
      "JP\n",
      "#skills 2679\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/JP.json\n",
      "********************\n",
      "MX\n",
      "#skills 897\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/MX.json\n",
      "********************\n",
      "UK\n",
      "#skills 29094\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/UK.json\n",
      "********************\n",
      "US\n",
      "#skills 51338\n",
      "Saving json in  ../datasets/DatasetsProcessed/2019/US.json\n"
     ]
    }
   ],
   "source": [
    "allf = getFiles( allyears[0] )\n",
    "print(allf)\n",
    "\n",
    "#NOTICE allo might contain repetitoins! (we filter them later)\n",
    "allo = {}\n",
    "for f in allf:\n",
    "    allo[f] = loadObjects(f)\n",
    "#list all markets\n",
    "for key,value in allo.items():\n",
    "    print(key)\n",
    "    print(len(value))\n",
    "    \n",
    "#filter repetitoins and skills without name or developer\n",
    "\n",
    "import json\n",
    "year = '2019'\n",
    "\n",
    "#Create a dictionary of unqiue skills per market\n",
    "for f in allf:\n",
    "    print('********************')\n",
    "    market_name = f.split('/')[3]\n",
    "    print(market_name)\n",
    "    skillsdict = _createSkillDict(allo[f], market_name, year)\n",
    "    print('#skills', len(skillsdict))\n",
    "    \n",
    "    skillsfound = []\n",
    "    for sk in skillsdict:\n",
    "        skill  = skillsdict[sk]\n",
    "        skname = skill['name']\n",
    "        skdev = skill['dev']      \n",
    "     \n",
    "    #save analysis in NewFullDataset json\n",
    "    path = '../datasets/DatasetsProcessed/'+year+'/'+market_name+'.json'\n",
    "    with open(path, 'w') as json_file:\n",
    "        print('Saving json in ',path)\n",
    "        json.dump(skillsdict, json_file)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.1.2 Load filtered Dataset for 2019 and map skill traceability from excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../datasets/Dataset_Mayy2019/Dataset_Mayy2019_traceability.csv\n",
      "['../datasets/DatasetsProcessed/2019/AU.json', '../datasets/DatasetsProcessed/2019/CA.json', '../datasets/DatasetsProcessed/2019/DE.json', '../datasets/DatasetsProcessed/2019/ES.json', '../datasets/DatasetsProcessed/2019/FR.json', '../datasets/DatasetsProcessed/2019/IN.json', '../datasets/DatasetsProcessed/2019/IT.json', '../datasets/DatasetsProcessed/2019/JP.json', '../datasets/DatasetsProcessed/2019/MX.json', '../datasets/DatasetsProcessed/2019/UK.json', '../datasets/DatasetsProcessed/2019/US.json']\n",
      "\n",
      "Total unique skills per market\n",
      "AU :  23123\n",
      "CA :  24700\n",
      "DE :  8928\n",
      "ES :  1286\n",
      "FR :  1341\n",
      "IN :  20989\n",
      "IT :  2210\n",
      "JP :  2679\n",
      "MX :  897\n",
      "UK :  29094\n",
      "US :  51338\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from excel\n",
    "#test the join of the dataframes\n",
    "year = '2019'\n",
    "print('loading', excelpaths[0])\n",
    "df2019 = loadExcelFile( excelpaths[0] )\n",
    "\n",
    "#from json\n",
    "datasetpath = \"../datasets/DatasetsProcessed/\"+year+\"/\"\n",
    "skillsmarket = reloadData(datasetpath)\n",
    "\n",
    "#join the two tables to create a general dataframe\n",
    "finaldf = updateDataframe(skillsmarket, df2019)\n",
    "\n",
    "#save dataframe\n",
    "finaldf.to_csv('../datasets/DatasetsProcessedTraceability/2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.1.3 Some checks on the final dataset for 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "finaldf = pd.read_csv('../datasets/DatasetsProcessedTraceability/2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id_new', 'id_aux', 'id', 'name', 'dev', 'cat', 'market',\n",
       "       'subcat', 'acc_linking', 'in_skill_purchase', 'cost', 'review_stars',\n",
       "       'skill_link', 'year', 'perm_requested_original', 'perm_found_norm',\n",
       "       'perm_requested_norm', 'policy_url', 'policy_text', 'traceability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check total number of skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>in_skill_purchase</th>\n",
       "      <th>skill_link</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166585.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>83292.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48089.091634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41646.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>83292.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>124938.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>166584.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0   id  in_skill_purchase  skill_link      year\n",
       "count  166585.000000  0.0                0.0         0.0  166585.0\n",
       "mean    83292.000000  NaN                NaN         NaN    2019.0\n",
       "std     48089.091634  NaN                NaN         NaN       0.0\n",
       "min         0.000000  NaN                NaN         NaN    2019.0\n",
       "25%     41646.000000  NaN                NaN         NaN    2019.0\n",
       "50%     83292.000000  NaN                NaN         NaN    2019.0\n",
       "75%    124938.000000  NaN                NaN         NaN    2019.0\n",
       "max    166584.000000  NaN                NaN         NaN    2019.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23123 unique skills found in AU\n",
      "24700 unique skills found in CA\n",
      "8928 unique skills found in DE\n",
      "1286 unique skills found in ES\n",
      "1341 unique skills found in FR\n",
      "20989 unique skills found in IN\n",
      "2210 unique skills found in IT\n",
      "2679 unique skills found in JP\n",
      "897 unique skills found in MX\n",
      "29094 unique skills found in UK\n",
      "51338 unique skills found in US\n"
     ]
    }
   ],
   "source": [
    "allmarkets = finaldf.market.unique()\n",
    "for mk in allmarkets:\n",
    "    print('{} unique skills found in {}'.format(len(finaldf.loc[finaldf['market'] == mk] ), mk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check how many of these skills have a policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 unique skills have a policy in AU\n",
      "158 unique skills have a policy in CA\n",
      "0 unique skills have a policy in DE\n",
      "0 unique skills have a policy in ES\n",
      "0 unique skills have a policy in FR\n",
      "111 unique skills have a policy in IN\n",
      "0 unique skills have a policy in IT\n",
      "0 unique skills have a policy in JP\n",
      "0 unique skills have a policy in MX\n",
      "287 unique skills have a policy in UK\n",
      "658 unique skills have a policy in US\n"
     ]
    }
   ],
   "source": [
    "allmarkets = finaldf.market.unique()\n",
    "for mk in allmarkets:\n",
    "    auxdf = finaldf.loc[ (finaldf['market']==mk) & (finaldf['perm_requested_norm'].notnull())]\n",
    "    print('{} unique skills have a policy in {}'.format(len(auxdf), mk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check number of unique developers per market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10123 unique devs in AU\n",
      "10773 unique devs in CA\n",
      "3165 unique devs in DE\n",
      "716 unique devs in ES\n",
      "641 unique devs in FR\n",
      "9197 unique devs in IN\n",
      "1095 unique devs in IT\n",
      "1056 unique devs in JP\n",
      "540 unique devs in MX\n",
      "12078 unique devs in UK\n",
      "19507 unique devs in US\n"
     ]
    }
   ],
   "source": [
    "allmarkets = finaldf.market.unique()\n",
    "for mk in allmarkets:\n",
    "    marketdf = finaldf.loc[finaldf['market'] == mk]\n",
    "    alldevs = marketdf.dev.unique()\n",
    "    print('{} unique devs in {}'.format(len(alldevs), mk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Broken, partial, complete skills per market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Market AU\n",
      "[nan 'B' 'C' 'P']\n",
      "\t 52 unique skills of type B\n",
      "\t 59 unique skills of type C\n",
      "\t 9 unique skills of type P\n",
      ">Market CA\n",
      "[nan 'C' 'P' 'B']\n",
      "\t 85 unique skills of type C\n",
      "\t 17 unique skills of type P\n",
      "\t 56 unique skills of type B\n",
      ">Market DE\n",
      "[nan]\n",
      ">Market ES\n",
      "[nan]\n",
      ">Market FR\n",
      "[nan]\n",
      ">Market IN\n",
      "[nan 'C' 'B' 'P']\n",
      "\t 55 unique skills of type C\n",
      "\t 43 unique skills of type B\n",
      "\t 13 unique skills of type P\n",
      ">Market IT\n",
      "[nan]\n",
      ">Market JP\n",
      "[nan]\n",
      ">Market MX\n",
      "[nan]\n",
      ">Market UK\n",
      "[nan 'B' 'C' 'P']\n",
      "\t 109 unique skills of type B\n",
      "\t 152 unique skills of type C\n",
      "\t 26 unique skills of type P\n",
      ">Market US\n",
      "[nan 'P' 'C' 'B']\n",
      "\t 69 unique skills of type P\n",
      "\t 337 unique skills of type C\n",
      "\t 252 unique skills of type B\n"
     ]
    }
   ],
   "source": [
    "allmarkets = finaldf.market.unique()\n",
    "totals = {'B':0, 'C':0, 'P':0}\n",
    "for mk in allmarkets:\n",
    "    print('>Market', mk)\n",
    "    marketdf = finaldf.loc[finaldf['market'] == mk]\n",
    "    alltypestraceability = marketdf.traceability.unique()\n",
    "    print(alltypestraceability)\n",
    "    for trace in alltypestraceability:        \n",
    "        tracdf = marketdf.loc[marketdf['traceability'] == trace]\n",
    "        if(tracdf is not None and len(tracdf)>0):\n",
    "            totals[trace]+=len(tracdf)\n",
    "            print('\\t {} unique skills of type {}'.format(len(tracdf), trace))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### check how many skills have the same name__dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU market, 23123 unique ids, 23123 total entries\n",
      "CA market, 24700 unique ids, 24700 total entries\n",
      "DE market, 8928 unique ids, 8928 total entries\n",
      "ES market, 1286 unique ids, 1286 total entries\n",
      "FR market, 1341 unique ids, 1341 total entries\n",
      "IN market, 20989 unique ids, 20989 total entries\n",
      "IT market, 2210 unique ids, 2210 total entries\n",
      "JP market, 2679 unique ids, 2679 total entries\n",
      "MX market, 897 unique ids, 897 total entries\n",
      "UK market, 29094 unique ids, 29094 total entries\n",
      "US market, 51338 unique ids, 51338 total entries\n"
     ]
    }
   ],
   "source": [
    "allmarkets = finaldf.market.unique()\n",
    "for mk in allmarkets:\n",
    "    marketdf = finaldf.loc[finaldf['market'] == mk]\n",
    "    print('{} market, {} unique ids, {} total entries'.format(mk, len(marketdf.id_aux.unique()), len(marketdf) ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load info from the 2020 json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../datasets/Dataset_July2020/AU/file.json', '../datasets/Dataset_July2020/CA/file.json', '../datasets/Dataset_July2020/DE/file.json', '../datasets/Dataset_July2020/ES/file.json', '../datasets/Dataset_July2020/FR/file.json', '../datasets/Dataset_July2020/IN/file.json', '../datasets/Dataset_July2020/IT/file.json', '../datasets/Dataset_July2020/JP/file.json', '../datasets/Dataset_July2020/MX/file.json', '../datasets/Dataset_July2020/UK/file.json', '../datasets/Dataset_July2020/US/file.json']\n",
      "../datasets/Dataset_July2020/AU/file.json\n",
      "68244\n",
      "../datasets/Dataset_July2020/CA/file.json\n",
      "42429\n",
      "../datasets/Dataset_July2020/DE/file.json\n",
      "53177\n",
      "../datasets/Dataset_July2020/ES/file.json\n",
      "49001\n",
      "../datasets/Dataset_July2020/FR/file.json\n",
      "2575\n",
      "../datasets/Dataset_July2020/IN/file.json\n",
      "133209\n",
      "../datasets/Dataset_July2020/IT/file.json\n",
      "5271\n",
      "../datasets/Dataset_July2020/JP/file.json\n",
      "46451\n",
      "../datasets/Dataset_July2020/MX/file.json\n",
      "2308\n",
      "../datasets/Dataset_July2020/UK/file.json\n",
      "41450\n",
      "../datasets/Dataset_July2020/US/file.json\n",
      "65543\n",
      "********************\n",
      "AU\n",
      "#skills 24062\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/AU.json\n",
      "********************\n",
      "CA\n",
      "#skills 26027\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/CA.json\n",
      "********************\n",
      "DE\n",
      "#skills 10287\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/DE.json\n",
      "********************\n",
      "ES\n",
      "#skills 5010\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/ES.json\n",
      "********************\n",
      "FR\n",
      "#skills 2288\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/FR.json\n",
      "********************\n",
      "IN\n",
      "#skills 31246\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/IN.json\n",
      "********************\n",
      "IT\n",
      "#skills 4203\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/IT.json\n",
      "********************\n",
      "JP\n",
      "#skills 3545\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/JP.json\n",
      "********************\n",
      "MX\n",
      "#skills 1972\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/MX.json\n",
      "********************\n",
      "UK\n",
      "#skills 34618\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/UK.json\n",
      "********************\n",
      "US\n",
      "#skills 55736\n",
      "Saving json in  ../datasets/DatasetsProcessed/2020/US.json\n"
     ]
    }
   ],
   "source": [
    "allf = getFiles( allyears[1] )\n",
    "print(allf)\n",
    "\n",
    "#NOTICE allo might contain repetitoins! (we filter them later)\n",
    "allo = {}\n",
    "for f in allf:\n",
    "    allo[f] = loadObjects(f)\n",
    "#list all markets\n",
    "for key,value in allo.items():\n",
    "    print(key)\n",
    "    print(len(value))\n",
    "    \n",
    "#filter repetitoins and skills without name or developer\n",
    "import json\n",
    "year = '2020'\n",
    "\n",
    "#Create a dictionary of unqiue skills per market\n",
    "for f in allf:\n",
    "    print('********************')\n",
    "    market_name = f.split('/')[3]\n",
    "    print(market_name)\n",
    "    skillsdict = _createSkillDict(allo[f], market_name, year)\n",
    "    print('#skills', len(skillsdict))\n",
    "    \n",
    "    skillsfound = []\n",
    "    for sk in skillsdict:\n",
    "        skill  = skillsdict[sk]\n",
    "        skname = skill['name']\n",
    "        skdev = skill['dev']      \n",
    "     \n",
    "    #save analysis in NewFullDataset json\n",
    "    path = '../datasets/DatasetsProcessed/'+year+'/'+market_name+'.json'\n",
    "    with open(path, 'w') as json_file:\n",
    "        print('Saving json in ',path)\n",
    "        json.dump(skillsdict, json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create final dataset w/ traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../datasets/Dataset_July2020/Dataset_july2020_traceability.csv\n",
      "['../datasets/DatasetsProcessed/2020/AU.json', '../datasets/DatasetsProcessed/2020/CA.json', '../datasets/DatasetsProcessed/2020/DE.json', '../datasets/DatasetsProcessed/2020/ES.json', '../datasets/DatasetsProcessed/2020/FR.json', '../datasets/DatasetsProcessed/2020/IN.json', '../datasets/DatasetsProcessed/2020/IT.json', '../datasets/DatasetsProcessed/2020/JP.json', '../datasets/DatasetsProcessed/2020/MX.json', '../datasets/DatasetsProcessed/2020/UK.json', '../datasets/DatasetsProcessed/2020/US.json']\n",
      "\n",
      "Total unique skills per market\n",
      "AU :  24062\n",
      "CA :  26027\n",
      "DE :  10287\n",
      "ES :  5010\n",
      "FR :  2288\n",
      "IN :  31246\n",
      "IT :  4203\n",
      "JP :  3545\n",
      "MX :  1972\n",
      "UK :  34618\n",
      "US :  55736\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from excel\n",
    "#test the join of the dataframes\n",
    "year = '2020'\n",
    "print('loading', excelpaths[1])\n",
    "df2019 = loadExcelFile( excelpaths[1] )\n",
    "\n",
    "#from json\n",
    "datasetpath = \"../datasets/DatasetsProcessed/\"+year+\"/\"\n",
    "skillsmarket = reloadData(datasetpath)\n",
    "\n",
    "#join the two tables to create a general dataframe\n",
    "finaldf = updateDataframe(skillsmarket, df2019)\n",
    "\n",
    "#save dataframe\n",
    "finaldf.to_csv('../datasets/DatasetsProcessedTraceability/'+year+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_new', 'id_aux', 'id', 'name', 'dev', 'cat', 'market', 'subcat',\n",
       "       'acc_linking', 'in_skill_purchase', 'cost', 'review_stars',\n",
       "       'skill_link', 'year', 'perm_requested_original', 'perm_found_norm',\n",
       "       'policy_url', 'policy_text', 'traceability', 'perm_requested_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Some checks and analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (9,10,15,16,17,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "finaldf = pd.read_csv('../datasets/DatasetsProcessedTraceability/2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### total numer of skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24062 unique skills found in AU\n",
      "26027 unique skills found in CA\n",
      "10287 unique skills found in DE\n",
      "5010 unique skills found in ES\n",
      "2288 unique skills found in FR\n",
      "31246 unique skills found in IN\n",
      "4203 unique skills found in IT\n",
      "3545 unique skills found in JP\n",
      "1972 unique skills found in MX\n",
      "34618 unique skills found in UK\n",
      "55736 unique skills found in US\n"
     ]
    }
   ],
   "source": [
    "allmarkets = finaldf.market.unique()\n",
    "for mk in allmarkets:\n",
    "    print('{} unique skills found in {}'.format(len(finaldf.loc[finaldf['market'] == mk] ), mk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load info from the 2021 json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../datasets/Dataset_Apri2021/AU/file.json', '../datasets/Dataset_Apri2021/CA/file.json', '../datasets/Dataset_Apri2021/DE/file.json', '../datasets/Dataset_Apri2021/ES/file.json', '../datasets/Dataset_Apri2021/FR/file.json', '../datasets/Dataset_Apri2021/IN/file.json', '../datasets/Dataset_Apri2021/IT/file.json', '../datasets/Dataset_Apri2021/JP/file.json', '../datasets/Dataset_Apri2021/MX/file.json', '../datasets/Dataset_Apri2021/UK/file.json', '../datasets/Dataset_Apri2021/US/file.json']\n",
      "../datasets/Dataset_Apri2021/AU/file.json\n",
      "24512\n",
      "../datasets/Dataset_Apri2021/CA/file.json\n",
      "27093\n",
      "../datasets/Dataset_Apri2021/DE/file.json\n",
      "10631\n",
      "../datasets/Dataset_Apri2021/ES/file.json\n",
      "5435\n",
      "../datasets/Dataset_Apri2021/FR/file.json\n",
      "2863\n",
      "../datasets/Dataset_Apri2021/IN/file.json\n",
      "28672\n",
      "../datasets/Dataset_Apri2021/IT/file.json\n",
      "4649\n",
      "../datasets/Dataset_Apri2021/JP/file.json\n",
      "3637\n",
      "../datasets/Dataset_Apri2021/MX/file.json\n",
      "2486\n",
      "../datasets/Dataset_Apri2021/UK/file.json\n",
      "37056\n",
      "../datasets/Dataset_Apri2021/US/file.json\n",
      "68667\n",
      "********************\n",
      "AU\n",
      "#skills 24512\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/AU.json\n",
      "********************\n",
      "CA\n",
      "#skills 27093\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/CA.json\n",
      "********************\n",
      "DE\n",
      "#skills 10631\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/DE.json\n",
      "********************\n",
      "ES\n",
      "#skills 5435\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/ES.json\n",
      "********************\n",
      "FR\n",
      "#skills 2863\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/FR.json\n",
      "********************\n",
      "IN\n",
      "#skills 28672\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/IN.json\n",
      "********************\n",
      "IT\n",
      "#skills 4649\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/IT.json\n",
      "********************\n",
      "JP\n",
      "#skills 3637\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/JP.json\n",
      "********************\n",
      "MX\n",
      "#skills 2486\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/MX.json\n",
      "********************\n",
      "UK\n",
      "#skills 37056\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/UK.json\n",
      "********************\n",
      "US\n",
      "#skills 68667\n",
      "Saving json in  ../datasets/DatasetsProcessed/2021/US.json\n"
     ]
    }
   ],
   "source": [
    "allf = getFiles( allyears[2] )\n",
    "print(allf)\n",
    "\n",
    "#NOTICE allo might contain repetitoins! (we filter them later)\n",
    "allo = {}\n",
    "for f in allf:\n",
    "    allo[f] = loadObjects(f)\n",
    "#list all markets\n",
    "for key,value in allo.items():\n",
    "    print(key)\n",
    "    print(len(value))\n",
    "    \n",
    "#filter repetitoins and skills without name or developer\n",
    "import json\n",
    "year = '2021'\n",
    "\n",
    "#Create a dictionary of unqiue skills per market\n",
    "for f in allf:\n",
    "    print('********************')\n",
    "    market_name = f.split('/')[3]\n",
    "    print(market_name)\n",
    "    skillsdict = _createSkillDict(allo[f], market_name, year)\n",
    "    print('#skills', len(skillsdict))\n",
    "    \n",
    "    skillsfound = []\n",
    "    for sk in skillsdict:\n",
    "        skill  = skillsdict[sk]\n",
    "        skname = skill['name']\n",
    "        skdev = skill['dev']      \n",
    "     \n",
    "    #save analysis in NewFullDataset json\n",
    "    path = '../datasets/DatasetsProcessed/'+year+'/'+market_name+'.json'\n",
    "    with open(path, 'w') as json_file:\n",
    "        print('Saving json in ',path)\n",
    "        json.dump(skillsdict, json_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create final dataset w/ traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../datasets/Dataset_Apri2021/Dataset_April2021_traceability.csv\n",
      "['../datasets/DatasetsProcessed/2021/AU.json', '../datasets/DatasetsProcessed/2021/CA.json', '../datasets/DatasetsProcessed/2021/DE.json', '../datasets/DatasetsProcessed/2021/ES.json', '../datasets/DatasetsProcessed/2021/FR.json', '../datasets/DatasetsProcessed/2021/IN.json', '../datasets/DatasetsProcessed/2021/IT.json', '../datasets/DatasetsProcessed/2021/JP.json', '../datasets/DatasetsProcessed/2021/MX.json', '../datasets/DatasetsProcessed/2021/UK.json', '../datasets/DatasetsProcessed/2021/US.json']\n",
      "\n",
      "Total unique skills per market\n",
      "AU :  24512\n",
      "CA :  27093\n",
      "DE :  10631\n",
      "ES :  5435\n",
      "FR :  2863\n",
      "IN :  28672\n",
      "IT :  4649\n",
      "JP :  3637\n",
      "MX :  2486\n",
      "UK :  37056\n",
      "US :  68667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from excel\n",
    "#test the join of the dataframes\n",
    "year = '2021'\n",
    "print('loading', excelpaths[2])\n",
    "df2019 = loadExcelFile( excelpaths[2] )\n",
    "\n",
    "#from json\n",
    "datasetpath = \"../datasets/DatasetsProcessed/\"+year+\"/\"\n",
    "skillsmarket = reloadData(datasetpath)\n",
    "\n",
    "#join the two tables to create a general dataframe\n",
    "finaldf = updateDataframe(skillsmarket, df2019)\n",
    "\n",
    "#save dataframe\n",
    "finaldf.to_csv('../datasets/DatasetsProcessedTraceability/'+year+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Some checks and analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "finaldf = pd.read_csv('../datasets/DatasetsProcessedTraceability/2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id_new', 'id_aux', 'id', 'name', 'dev', 'cat', 'market',\n",
       "       'subcat', 'acc_linking', 'in_skill_purchase', 'cost', 'review_stars',\n",
       "       'skill_link', 'year', 'perm_requested_original', 'perm_found_norm',\n",
       "       'policy_url', 'policy_text', 'traceability', 'perm_requested_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Total number of skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24512 unique skills found in AU\n",
      "27093 unique skills found in CA\n",
      "10631 unique skills found in DE\n",
      "5435 unique skills found in ES\n",
      "2863 unique skills found in FR\n",
      "28672 unique skills found in IN\n",
      "4649 unique skills found in IT\n",
      "3637 unique skills found in JP\n",
      "2486 unique skills found in MX\n",
      "37056 unique skills found in UK\n",
      "68667 unique skills found in US\n"
     ]
    }
   ],
   "source": [
    "allmarkets = finaldf.market.unique()\n",
    "for mk in allmarkets:\n",
    "    print('{} unique skills found in {}'.format(len(finaldf.loc[finaldf['market'] == mk] ), mk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_aux</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>dev</th>\n",
       "      <th>cat</th>\n",
       "      <th>market</th>\n",
       "      <th>subcat</th>\n",
       "      <th>acc_linking</th>\n",
       "      <th>in_skill_purchase</th>\n",
       "      <th>cost</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>skill_link</th>\n",
       "      <th>perm_requested_original</th>\n",
       "      <th>perm_found_norm</th>\n",
       "      <th>policy_url</th>\n",
       "      <th>policy_text</th>\n",
       "      <th>traceability</th>\n",
       "      <th>perm_requested_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Insureblocks Blockchain for insurance__by Insu...</td>\n",
       "      <td>B07GNDDNLG</td>\n",
       "      <td>Insureblocks Blockchain for insurance</td>\n",
       "      <td>by Insureblocks</td>\n",
       "      <td>Business &amp; Finance</td>\n",
       "      <td>AU</td>\n",
       "      <td>Business &amp; Finance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No customer reviews</td>\n",
       "      <td>https://www.amazon.com.au/Insureblocks-Blockch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bitcoin Portfolio Tracker__by Phocus Labs__B07...</td>\n",
       "      <td>B07C2TJPLV</td>\n",
       "      <td>Bitcoin Portfolio Tracker</td>\n",
       "      <td>by Phocus Labs</td>\n",
       "      <td>Business &amp; Finance</td>\n",
       "      <td>AU</td>\n",
       "      <td>Business &amp; Finance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No customer reviews</td>\n",
       "      <td>https://www.amazon.com.au/Phocus-Labs-Bitcoin-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bag Facts__by Priya__B07H57WNTJ</td>\n",
       "      <td>B07H57WNTJ</td>\n",
       "      <td>Bag Facts</td>\n",
       "      <td>by Priya</td>\n",
       "      <td>Education &amp; Reference</td>\n",
       "      <td>AU</td>\n",
       "      <td>Education &amp; Reference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No customer reviews</td>\n",
       "      <td>https://www.amazon.com.au/Priya-Bag-Facts/dp/B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My Baby Facts__by Right From Left Software__B0...</td>\n",
       "      <td>B071G3XDXH</td>\n",
       "      <td>My Baby Facts</td>\n",
       "      <td>by Right From Left Software</td>\n",
       "      <td>Education &amp; Reference</td>\n",
       "      <td>AU</td>\n",
       "      <td>Education &amp; Reference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No customer reviews</td>\n",
       "      <td>https://www.amazon.com.au/Right-From-Left-Soft...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bloomberg Market Minute__by Bloomberg L.P.__B0...</td>\n",
       "      <td>B07DVFN26J</td>\n",
       "      <td>Bloomberg Market Minute</td>\n",
       "      <td>by Bloomberg L.P.</td>\n",
       "      <td>Fitness &amp; Sports</td>\n",
       "      <td>AU</td>\n",
       "      <td>News</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No customer reviews</td>\n",
       "      <td>https://www.amazon.com.au/Bloomberg-L-P-Market...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             id_aux          id  \\\n",
       "0           0  Insureblocks Blockchain for insurance__by Insu...  B07GNDDNLG   \n",
       "1           1  Bitcoin Portfolio Tracker__by Phocus Labs__B07...  B07C2TJPLV   \n",
       "2           2                    Bag Facts__by Priya__B07H57WNTJ  B07H57WNTJ   \n",
       "3           3  My Baby Facts__by Right From Left Software__B0...  B071G3XDXH   \n",
       "4           4  Bloomberg Market Minute__by Bloomberg L.P.__B0...  B07DVFN26J   \n",
       "\n",
       "                                    name                          dev  \\\n",
       "0  Insureblocks Blockchain for insurance              by Insureblocks   \n",
       "1              Bitcoin Portfolio Tracker               by Phocus Labs   \n",
       "2                              Bag Facts                     by Priya   \n",
       "3                          My Baby Facts  by Right From Left Software   \n",
       "4                Bloomberg Market Minute            by Bloomberg L.P.   \n",
       "\n",
       "                     cat market                 subcat acc_linking  \\\n",
       "0     Business & Finance     AU     Business & Finance         NaN   \n",
       "1     Business & Finance     AU     Business & Finance         NaN   \n",
       "2  Education & Reference     AU  Education & Reference         NaN   \n",
       "3  Education & Reference     AU  Education & Reference         NaN   \n",
       "4       Fitness & Sports     AU                   News         NaN   \n",
       "\n",
       "  in_skill_purchase cost         review_stars  \\\n",
       "0               NaN  NaN  No customer reviews   \n",
       "1               NaN  NaN  No customer reviews   \n",
       "2               NaN  NaN  No customer reviews   \n",
       "3               NaN  NaN  No customer reviews   \n",
       "4               NaN  NaN  No customer reviews   \n",
       "\n",
       "                                          skill_link  perm_requested_original  \\\n",
       "0  https://www.amazon.com.au/Insureblocks-Blockch...                      NaN   \n",
       "1  https://www.amazon.com.au/Phocus-Labs-Bitcoin-...                      NaN   \n",
       "2  https://www.amazon.com.au/Priya-Bag-Facts/dp/B...                      NaN   \n",
       "3  https://www.amazon.com.au/Right-From-Left-Soft...                      NaN   \n",
       "4  https://www.amazon.com.au/Bloomberg-L-P-Market...                      NaN   \n",
       "\n",
       "   perm_found_norm  policy_url  policy_text  traceability  perm_requested_norm  \n",
       "0              NaN         NaN          NaN           NaN                  NaN  \n",
       "1              NaN         NaN          NaN           NaN                  NaN  \n",
       "2              NaN         NaN          NaN           NaN                  NaN  \n",
       "3              NaN         NaN          NaN           NaN                  NaN  \n",
       "4              NaN         NaN          NaN           NaN                  NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
